{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project\n",
    "\n",
    "##### Creating Regression Models for data available on https://archive.ics.uci.edu/ml/datasets/Computer+Hardware\n",
    "\n",
    "##### Analysing and comparing with the values published and the estimated in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Modules used here for the primary use\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the dataset used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>MYCT</th>\n",
       "      <th>MMIN</th>\n",
       "      <th>MMAX</th>\n",
       "      <th>CACH</th>\n",
       "      <th>CHMIN</th>\n",
       "      <th>CHMAX</th>\n",
       "      <th>PRP</th>\n",
       "      <th>ERP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adviser</td>\n",
       "      <td>32/60</td>\n",
       "      <td>125</td>\n",
       "      <td>256</td>\n",
       "      <td>6000</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>470v/7</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>269</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>470v/7a</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>220</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>470v/7b</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>172</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amdahl</td>\n",
       "      <td>470v/7c</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>16000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vendor_name model_name  MYCT  MMIN   MMAX  CACH  CHMIN  CHMAX  PRP  ERP\n",
       "0     adviser      32/60   125   256   6000   256     16    128  198  199\n",
       "1      amdahl     470v/7    29  8000  32000    32      8     32  269  253\n",
       "2      amdahl    470v/7a    29  8000  32000    32      8     32  220  253\n",
       "3      amdahl    470v/7b    29  8000  32000    32      8     32  172  253\n",
       "4      amdahl    470v/7c    29  8000  16000    32      8     16  132  132"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('dataset/machine.data',names=['vendor_name','model_name','MYCT','MMIN','MMAX','CACH',\n",
    "                                      'CHMIN','CHMAX','PRP','ERP'])\n",
    "data_trn=data.copy()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>MYCT</th>\n",
       "      <th>MMIN</th>\n",
       "      <th>MMAX</th>\n",
       "      <th>CACH</th>\n",
       "      <th>CHMIN</th>\n",
       "      <th>CHMAX</th>\n",
       "      <th>PRP</th>\n",
       "      <th>ERP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32/60</td>\n",
       "      <td>125</td>\n",
       "      <td>256</td>\n",
       "      <td>6000</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>470v/7</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>269</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>470v/7a</td>\n",
       "      <td>29</td>\n",
       "      <td>8000</td>\n",
       "      <td>32000</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>220</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendor_name model_name  MYCT  MMIN   MMAX  CACH  CHMIN  CHMAX  PRP  ERP\n",
       "0            0      32/60   125   256   6000   256     16    128  198  199\n",
       "1            1     470v/7    29  8000  32000    32      8     32  269  253\n",
       "2            1    470v/7a    29  8000  32000    32      8     32  220  253"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Encondind the label vendor_name for optimization purposes'''\n",
    "transformer=preprocessing.LabelEncoder()\n",
    "vendor_name=transformer.fit_transform(data_trn.vendor_name)\n",
    "data_trn.vendor_name=vendor_name\n",
    "data_trn.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "\n",
    "X=data_trn[['vendor_name','MYCT','MMIN','MMAX','CACH','CHMIN','CHMAX']]#Features\n",
    "y=data_trn['PRP']#Label\n",
    "#Splitting the data_set\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0,test_size=0.15)\n",
    "\n",
    "#Normalizated features for future models\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model: KNeighborsRegressor\n",
    "###### For this Model we'll use the KN Regression, without normalization to see how this affects the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For this number of neighbors 1, this is the score of the model: 0.9319133094864283\n",
      "For this number of neighbors 2, this is the score of the model: 0.9444422413932635\n",
      "For this number of neighbors 3, this is the score of the model: 0.959928027666726\n",
      "For this number of neighbors 4, this is the score of the model: 0.9455338644934691\n",
      "For this number of neighbors 5, this is the score of the model: 0.9093684023113154\n",
      "For this number of neighbors 6, this is the score of the model: 0.8863751625312248\n",
      "For this number of neighbors 7, this is the score of the model: 0.8708104765626368\n",
      "For this number of neighbors 8, this is the score of the model: 0.8402558399964392\n",
      "For this number of neighbors 9, this is the score of the model: 0.7999883702876436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "#finding the best parameters to build the model \n",
    "for i in range(1,10):\n",
    "    knnreg=KNeighborsRegressor(n_neighbors=i).fit(X_train,y_train)\n",
    "    print(f'For this number of neighbors {i}, this is the score of the model: {knnreg.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the prediction against the published value of perfomance: \n",
      " [(39.333333333333336, 16), (49.0, 63), (324.3333333333333, 318), (68.0, 75), (36.333333333333336, 16), (98.0, 66), (9.666666666666666, 12), (145.66666666666666, 141), (183.66666666666666, 214)]\n"
     ]
    }
   ],
   "source": [
    "#Considerating the feature above, we'll use 3 as the number of neighbors for this model\n",
    "knnreg=KNeighborsRegressor(n_neighbors=3).fit(X_train,y_train)\n",
    "x=zip(list(knnreg.predict(X_test)),y_test.tolist())\n",
    "print('Comparing the prediction against the published value of perfomance: \\n',list(x)[1:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Model: Linear regression\n",
    "###### For this Model we'll use the Linear regression (based on the squared error), with and without normalization to see how this affects the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg= LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linreg.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.905\n"
     ]
    }
   ],
   "source": [
    "#Using normalization\n",
    "linreg= LinearRegression().fit(X_train_scaled,y_train)\n",
    "\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linreg.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linreg.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the prediction against the published value of perfomance: \n",
      " [(5.634793336639916, 16), (88.617527673032, 63), (329.4614687399462, 318), (91.76017692143772, 75), (13.954745233956508, 16), (92.85222357620522, 66), (43.78858601717292, 12), (267.6093839013894, 141), (198.64301799478852, 214)]\n"
     ]
    }
   ],
   "source": [
    "linreg= LinearRegression().fit(X_train,y_train)\n",
    "x=zip(list(abs(linreg.predict(X_test))),y_test.tolist())\n",
    "print('Comparing the prediction against the published value of perfomance: \\n',list(x)[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Model: Ridge regression\n",
    "###### For this Model we'll use the Ridge regression (based on the squared error of the weights used), with and without normalization to see how this affects the model and variating the regularization of the model for avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For this value of alpha: 0.001, those are the scores:\n",
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.905 \n",
      "\n",
      "For this value of alpha: 0.1, those are the scores:\n",
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.905 \n",
      "\n",
      "For this value of alpha: 1, those are the scores:\n",
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.905 \n",
      "\n",
      "For this value of alpha: 2, those are the scores:\n",
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.905 \n",
      "\n",
      "For this value of alpha: 5, those are the scores:\n",
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.905 \n",
      "\n",
      "For this value of alpha: 10, those are the scores:\n",
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.905 \n",
      "\n",
      "For this value of alpha: 50, those are the scores:\n",
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.905 \n",
      "\n",
      "For this value of alpha: 100, those are the scores:\n",
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.905 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "#values that control the regularization of the model\n",
    "alpha_values=[1e-3,0.1,1,2,5,10,50,100]\n",
    "for i in range(0,len(alpha_values)):\n",
    "    linridge= Ridge(alpha=alpha_values[i]).fit(X_train,y_train)\n",
    "    print(f'For this value of alpha: {alpha_values[i]}, those are the scores:')\n",
    "    print('R-squared score (training): {:.3f}'\n",
    "     .format(linridge.score(X_train, y_train)))\n",
    "    print('R-squared score (test): {:.3f} \\n'\n",
    "     .format(linridge.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For this value of alpha: 0.001, those are the scores with normalization:\n",
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.905 \n",
      "\n",
      "For this value of alpha: 0.1, those are the scores with normalization:\n",
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.907 \n",
      "\n",
      "For this value of alpha: 1, those are the scores with normalization:\n",
      "R-squared score (training): 0.846\n",
      "R-squared score (test): 0.910 \n",
      "\n",
      "For this value of alpha: 2, those are the scores with normalization:\n",
      "R-squared score (training): 0.827\n",
      "R-squared score (test): 0.899 \n",
      "\n",
      "For this value of alpha: 5, those are the scores with normalization:\n",
      "R-squared score (training): 0.765\n",
      "R-squared score (test): 0.844 \n",
      "\n",
      "For this value of alpha: 10, those are the scores with normalization:\n",
      "R-squared score (training): 0.669\n",
      "R-squared score (test): 0.745 \n",
      "\n",
      "For this value of alpha: 50, those are the scores with normalization:\n",
      "R-squared score (training): 0.311\n",
      "R-squared score (test): 0.349 \n",
      "\n",
      "For this value of alpha: 100, those are the scores with normalization:\n",
      "R-squared score (training): 0.184\n",
      "R-squared score (test): 0.207 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using normalization\n",
    "alpha_values=[1e-3,0.1,1,2,5,10,50,100]\n",
    "for i in range(0,len(alpha_values)):\n",
    "    linridge= Ridge(alpha=alpha_values[i]).fit(X_train_scaled,y_train)\n",
    "    print(f'For this value of alpha: {alpha_values[i]}, those are the scores with normalization:')\n",
    "    print('R-squared score (training): {:.3f}'\n",
    "     .format(linridge.score(X_train_scaled, y_train)))\n",
    "    print('R-squared score (test): {:.3f} \\n'\n",
    "     .format(linridge.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the prediction against the published value of perfomance: \n",
      " [(2.0693701973432397, 16), (107.79144895858254, 63), (313.65263960223393, 318), (91.639864155838, 75), (7.213240952566601, 16), (96.90001725378589, 66), (13.035056872323935, 12), (256.98068918347934, 141), (198.90363813074646, 214)]\n"
     ]
    }
   ],
   "source": [
    "#As we saw above, the best value was confirming using normalization and is around 1.0\n",
    "linridge= Ridge(alpha=1.0).fit(X_train_scaled,y_train)\n",
    "x=zip(list(abs(linridge.predict(X_test_scaled))),y_test.tolist())\n",
    "print('Comparing the prediction against the published value of perfomance: \\n',list(x)[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Model: Lasso regression\n",
    "###### For this Model we'll use the Lasso regression (based on the absolute value of the weights used) with and without normalization to see how this affects the model and variating the regularization of the model for avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For this value of alpha: 0.001, those are the scores:\n",
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.905 \n",
      "\n",
      "For this value of alpha: 0.1, those are the scores:\n",
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.905 \n",
      "\n",
      "For this value of alpha: 1, those are the scores:\n",
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.905 \n",
      "\n",
      "For this value of alpha: 2, those are the scores:\n",
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.905 \n",
      "\n",
      "For this value of alpha: 5, those are the scores:\n",
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.906 \n",
      "\n",
      "For this value of alpha: 10, those are the scores:\n",
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.908 \n",
      "\n",
      "For this value of alpha: 50, those are the scores:\n",
      "R-squared score (training): 0.858\n",
      "R-squared score (test): 0.911 \n",
      "\n",
      "For this value of alpha: 100, those are the scores:\n",
      "R-squared score (training): 0.858\n",
      "R-squared score (test): 0.912 \n",
      "\n",
      "For this value of alpha: 1000, those are the scores:\n",
      "R-squared score (training): 0.787\n",
      "R-squared score (test): 0.907 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "#values that control the regularization of the model\n",
    "alpha_values=[1e-3,0.1,1,2,5,10,50,100,1000]\n",
    "for i in range(0,len(alpha_values)):\n",
    "    linlasso= Lasso(alpha=alpha_values[i],max_iter=10000).fit(X_train,y_train)\n",
    "    print(f'For this value of alpha: {alpha_values[i]}, those are the scores:')\n",
    "    print('R-squared score (training): {:.3f}'\n",
    "     .format(linlasso.score(X_train, y_train)))\n",
    "    print('R-squared score (test): {:.3f} \\n'\n",
    "     .format(linlasso.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For this value of alpha: 0.001, those are the scores:\n",
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.905 \n",
      "\n",
      "For this value of alpha: 0.1, those are the scores:\n",
      "R-squared score (training): 0.859\n",
      "R-squared score (test): 0.909 \n",
      "\n",
      "For this value of alpha: 1, those are the scores:\n",
      "R-squared score (training): 0.850\n",
      "R-squared score (test): 0.910 \n",
      "\n",
      "For this value of alpha: 2, those are the scores:\n",
      "R-squared score (training): 0.835\n",
      "R-squared score (test): 0.886 \n",
      "\n",
      "For this value of alpha: 5, those are the scores:\n",
      "R-squared score (training): 0.762\n",
      "R-squared score (test): 0.769 \n",
      "\n",
      "For this value of alpha: 10, those are the scores:\n",
      "R-squared score (training): 0.639\n",
      "R-squared score (test): 0.641 \n",
      "\n",
      "For this value of alpha: 50, those are the scores:\n",
      "R-squared score (training): 0.000\n",
      "R-squared score (test): -0.001 \n",
      "\n",
      "For this value of alpha: 100, those are the scores:\n",
      "R-squared score (training): 0.000\n",
      "R-squared score (test): -0.001 \n",
      "\n",
      "For this value of alpha: 1000, those are the scores:\n",
      "R-squared score (training): 0.000\n",
      "R-squared score (test): -0.001 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#using normalization\n",
    "alpha_values=[1e-3,0.1,1,2,5,10,50,100,1000]\n",
    "for i in range(0,len(alpha_values)):\n",
    "    linlasso= Lasso(alpha=alpha_values[i],max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    print(f'For this value of alpha: {alpha_values[i]}, those are the scores:')\n",
    "    print('R-squared score (training): {:.3f}'\n",
    "     .format(linlasso.score(X_train_scaled, y_train)))\n",
    "    print('R-squared score (test): {:.3f} \\n'\n",
    "     .format(linlasso.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the prediction against the published value of perfomance: \n",
      " [(2.0693701973432397, 16), (107.79144895858254, 63), (313.65263960223393, 318), (91.639864155838, 75), (7.213240952566601, 16), (96.90001725378589, 66), (13.035056872323935, 12), (256.98068918347934, 141), (198.90363813074646, 214)]\n"
     ]
    }
   ],
   "source": [
    "#As we saw above, the best way to build a model usind Lasso for this dataset is use Normalization\n",
    "#for memorie usage and processing purposes, and takes alpha around the value of 1.0\n",
    "linlasso= Ridge(alpha=1.0,max_iter=10000).fit(X_train_scaled,y_train)\n",
    "x=zip(list(abs(linlasso.predict(X_test_scaled))),y_test.tolist())\n",
    "print('Comparing the prediction against the published value of perfomance: \\n',list(x)[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Features for Linear Regression\n",
    "###### It's Possible to add some polynomial features to a linear regression. Basically the number of variables or features will order the degree of polymonial expression.\n",
    "###### We can combine this features with normal regressions as Linear,Ridge and Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the degree \"1\" of the polynomial those are the scores for the models:\n",
      "\n",
      "KN regression:    \t (training):0.932\t(test):0.960\n",
      "Linear regression:\t (training):0.859\t(test):0.905\n",
      "Ridge regression:\t (training):0.846\t(test):0.910\n",
      "Lasso regression:\t (training):0.846\t(test):0.910\n",
      "\n",
      "For the degree \"2\" of the polynomial those are the scores for the models:\n",
      "\n",
      "KN regression:    \t (training):0.932\t(test):0.960\n",
      "Linear regression:\t (training):0.974\t(test):0.816\n",
      "Ridge regression:\t (training):0.946\t(test):0.893\n",
      "Lasso regression:\t (training):0.946\t(test):0.893\n",
      "\n",
      "For the degree \"3\" of the polynomial those are the scores for the models:\n",
      "\n",
      "KN regression:    \t (training):0.932\t(test):0.960\n",
      "Linear regression:\t (training):0.980\t(test):-14.019\n",
      "Ridge regression:\t (training):0.960\t(test):0.882\n",
      "Lasso regression:\t (training):0.960\t(test):0.882\n",
      "\n",
      "For the degree \"4\" of the polynomial those are the scores for the models:\n",
      "\n",
      "KN regression:    \t (training):0.932\t(test):0.960\n",
      "Linear regression:\t (training):0.997\t(test):-3970.115\n",
      "Ridge regression:\t (training):0.969\t(test):0.890\n",
      "Lasso regression:\t (training):0.969\t(test):0.890\n",
      "\n",
      "For the degree \"5\" of the polynomial those are the scores for the models:\n",
      "\n",
      "KN regression:    \t (training):0.931\t(test):0.960\n",
      "Linear regression:\t (training):0.998\t(test):-856271.742\n",
      "Ridge regression:\t (training):0.974\t(test):0.703\n",
      "Lasso regression:\t (training):0.974\t(test):0.703\n",
      "\n",
      "For the degree \"6\" of the polynomial those are the scores for the models:\n",
      "\n",
      "KN regression:    \t (training):0.931\t(test):0.960\n",
      "Linear regression:\t (training):0.997\t(test):-14529765.158\n",
      "Ridge regression:\t (training):0.977\t(test):0.541\n",
      "Lasso regression:\t (training):0.977\t(test):0.541\n",
      "\n",
      "For the degree \"7\" of the polynomial those are the scores for the models:\n",
      "\n",
      "KN regression:    \t (training):0.931\t(test):0.960\n",
      "Linear regression:\t (training):0.994\t(test):-112435590.673\n",
      "Ridge regression:\t (training):0.978\t(test):0.852\n",
      "Lasso regression:\t (training):0.978\t(test):0.852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,8):\n",
    "    poly=PolynomialFeatures(degree=i)\n",
    "    #splitting the data with the addition of polynomial features\n",
    "    X_train_polynomial=poly.fit_transform(X)\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X_train_polynomial,y,\n",
    "                                                   random_state=0,test_size=0.15)\n",
    "    #Normalizated features for future models\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    #creating the models again\n",
    "    knnreg=KNeighborsRegressor(n_neighbors=3).fit(X_train,y_train)\n",
    "    linreg= LinearRegression().fit(X_train,y_train)\n",
    "    linridge= Ridge(alpha=1.0).fit(X_train_scaled,y_train)\n",
    "    linlasso= Ridge(alpha=1.0,max_iter=10000).fit(X_train_scaled,y_train)\n",
    "    \n",
    "    print(f'For the degree \"{i}\" of the polynomial those are the scores for the models:\\n')\n",
    "    \n",
    "    print(f'KN regression:    \\t (training):{knnreg.score(X_train,y_train):.3f}\\t(test):{knnreg.score(X_test,y_test):.3f}')\n",
    "    \n",
    "    print(f'Linear regression:\\t (training):{linreg.score(X_train,y_train):.3f}\\t(test):{linreg.score(X_test,y_test):.3f}')\n",
    "    \n",
    "    print(f'Ridge regression:\\t (training):{linridge.score(X_train_scaled,y_train):.3f}\\t(test):{linridge.score(X_test_scaled,y_test):.3f}')\n",
    "    \n",
    "    print(f'Lasso regression:\\t (training):{linlasso.score(X_train_scaled,y_train):.3f}\\t(test):{linlasso.score(X_test_scaled,y_test):.3f}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The cell above shows how complex the model are, usually regard to the degree, more it's tends to overfitting and in some cases, to not classify right, as we see in the Linear Regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the prediction[Ridge and Lasso] against the published value of perfomance: \n",
      " \n",
      " [(27.56156819616463, 27.56156819616463, 16), (103.12885624632241, 103.12885624632241, 63), (229.29990425515183, 229.29990425515183, 318), (82.72720282129607, 82.72720282129607, 75), (25.005919025838416, 25.005919025838416, 16), (79.40490277223498, 79.40490277223498, 66), (8.039566100948413, 8.039566100948413, 12), (182.60385968116648, 182.60385968116648, 141), (155.14093099668125, 155.14093099668125, 214)]\n"
     ]
    }
   ],
   "source": [
    "poly=PolynomialFeatures(degree=i)\n",
    "#splitting the data with the addition of polynomial features\n",
    "X_train_polynomial=poly.fit_transform(X)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_train_polynomial,y,\n",
    "                                               random_state=0,test_size=0.15)\n",
    "#Normalizated features for future models\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#creating the models again\n",
    "linridge= Ridge(alpha=1.0).fit(X_train_scaled,y_train)\n",
    "linlasso= Ridge(alpha=1.0,max_iter=10000).fit(X_train_scaled,y_train)\n",
    "\n",
    "x=zip(linridge.predict(X_test_scaled),linlasso.predict(X_test_scaled),y_test.tolist())\n",
    "print('Comparing the prediction[Ridge and Lasso] against the published value of perfomance: \\n \\n',list(x)[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks Regressor\n",
    "#### Getting a different prediction using Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data_set\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0,test_size=0.2)\n",
    "\n",
    "#Normalizated features for future models\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the activation type \"tanh\" and setting the alpha regularization parameter as 100 the scores are:        \n",
      "training:0.9379326005931539        \t test:0.9341754910322173 \n",
      "\n",
      "For the activation type \"tanh\" and setting the alpha regularization parameter as 110 the scores are:        \n",
      "training:0.931044097774645        \t test:0.9293675680429859 \n",
      "\n",
      "For the activation type \"tanh\" and setting the alpha regularization parameter as 125 the scores are:        \n",
      "training:0.9403445552899986        \t test:0.9266088584193414 \n",
      "\n",
      "For the activation type \"tanh\" and setting the alpha regularization parameter as 135 the scores are:        \n",
      "training:0.9408937438871837        \t test:0.9311781303176222 \n",
      "\n",
      "For the activation type \"tanh\" and setting the alpha regularization parameter as 150 the scores are:        \n",
      "training:0.9356071521705652        \t test:0.9291640807989081 \n",
      "\n",
      "For the activation type \"tanh\" and setting the alpha regularization parameter as 200 the scores are:        \n",
      "training:0.8726680210059334        \t test:0.9248117882309868 \n",
      "\n",
      "For the activation type \"tanh\" and setting the alpha regularization parameter as 500 the scores are:        \n",
      "training:0.7985243059442115        \t test:0.926519549410427 \n",
      "\n",
      "For the activation type \"tanh\" and setting the alpha regularization parameter as 1000 the scores are:        \n",
      "training:0.6586657720879899        \t test:0.8832392968241214 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "#Defining the parameters for a better perfomance and data usage\n",
    "for  thisactivation in ['tanh']:\n",
    "    for thisalpha in [100,110,125,135,150,200,500,1000]:\n",
    "        mlpreg = MLPRegressor(hidden_layer_sizes = [50,50],\n",
    "                             activation = thisactivation,\n",
    "                             alpha = thisalpha,\n",
    "                             solver = 'lbfgs',max_iter=5000,random_state=0).fit(X_train_scaled, y_train)\n",
    "        print(f'For the activation type \"{thisactivation}\" and setting the alpha regularization parameter as {thisalpha} the scores are:\\\n",
    "        \\ntraining:{mlpreg.score(X_train_scaled,y_train)}\\\n",
    "        \\t test:{mlpreg.score(X_test_scaled,y_test)} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the prediction[Neura Network Regressor] against the published value of perfomance: \n",
      " \n",
      " [(38.14779644958861, 16), (58.224130536113364, 63), (268.3595863289079, 318), (58.01905744201565, 75), (37.91415948744907, 16), (63.211961307260935, 66), (36.45713264005627, 12), (192.03110864070942, 141), (177.17096173365934, 214)]\n"
     ]
    }
   ],
   "source": [
    "#Looking to the results above,we'll use the parameter alpha as 100, to look to the results\n",
    "mlpreg = MLPRegressor(hidden_layer_sizes = [50,50],\n",
    "                             activation = 'tanh',\n",
    "                             alpha = 100,\n",
    "                             solver = 'lbfgs',max_iter=5000,random_state=0).fit(X_train_scaled, y_train)\n",
    "\n",
    "x=zip(mlpreg.predict(X_test_scaled),y_test.tolist())\n",
    "print('Comparing the prediction[Neura Network Regressor] against the published value of perfomance: \\n \\n',list(x)[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models\n",
    "#### Defined all the models, we'll try to compare all the predictions to the published and estimated perfomance of the computers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Published</th>\n",
       "      <th>Estimated</th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>KNeighbors Regression</th>\n",
       "      <th>Ridge Regression</th>\n",
       "      <th>Lasso Regression</th>\n",
       "      <th>Neural Network Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>343</td>\n",
       "      <td>84</td>\n",
       "      <td>338</td>\n",
       "      <td>338</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>269</td>\n",
       "      <td>253</td>\n",
       "      <td>306</td>\n",
       "      <td>220</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>253</td>\n",
       "      <td>306</td>\n",
       "      <td>220</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>172</td>\n",
       "      <td>253</td>\n",
       "      <td>306</td>\n",
       "      <td>220</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>188</td>\n",
       "      <td>160</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>48</td>\n",
       "      <td>53</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>67</td>\n",
       "      <td>47</td>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>45</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Published  Estimated  Linear Regression  KNeighbors Regression  \\\n",
       "0          198        199                343                     84   \n",
       "1          269        253                306                    220   \n",
       "2          220        253                306                    220   \n",
       "3          172        253                306                    220   \n",
       "4          132        132                188                    160   \n",
       "..         ...        ...                ...                    ...   \n",
       "204         42         37                 24                     28   \n",
       "205         46         50                 44                     24   \n",
       "206         52         41                 48                     53   \n",
       "207         67         47                 49                     43   \n",
       "208         45         25                 10                     35   \n",
       "\n",
       "     Ridge Regression  Lasso Regression  Neural Network Regression  \n",
       "0                 338               338                        196  \n",
       "1                 291               291                        218  \n",
       "2                 291               291                        218  \n",
       "3                 291               291                        218  \n",
       "4                 178               178                        125  \n",
       "..                ...               ...                        ...  \n",
       "204                30                30                         41  \n",
       "205                52                52                         65  \n",
       "206                47                47                         51  \n",
       "207                47                47                         64  \n",
       "208                 6                 6                         39  \n",
       "\n",
       "[209 rows x 7 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feeding all the models with the entire dataset to estimate the result\n",
    "\n",
    "#Splitting the data_set\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0,test_size=0.15)\n",
    "\n",
    "#Normalizated features for future models\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Creating a frame to facilitating the visualization\n",
    "comparison=pd.DataFrame()\n",
    "\n",
    "#Normalizating the X \n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#evocating the models\n",
    "linreg= LinearRegression().fit(X_train,y_train)\n",
    "linear=[int(x) for x in linreg.predict(X)]\n",
    "\n",
    "knnreg=KNeighborsRegressor(n_neighbors=3).fit(X_train,y_train)\n",
    "kneighbor=[int(x) for x in knnreg.predict(X)]\n",
    "\n",
    "linridge= Ridge(alpha=1.0).fit(X_train_scaled,y_train)\n",
    "ridge=[int(x) for x in linridge.predict(X_scaled)]\n",
    "\n",
    "linlasso= Ridge(alpha=1.0,max_iter=10000).fit(X_train_scaled,y_train)\n",
    "lasso=[int(x) for x in linlasso.predict(X_scaled)]\n",
    "\n",
    "mlpreg = MLPRegressor(hidden_layer_sizes = [50,50],\n",
    "                             activation = 'tanh',\n",
    "                             alpha = 100,\n",
    "                             solver = 'lbfgs',max_iter=5000,random_state=0).fit(X_train_scaled, y_train)\n",
    "neural=[int(x) for x in mlpreg.predict(X_scaled)]\n",
    "\n",
    "comparison['Published']=data['PRP']\n",
    "comparison['Estimated']=data['ERP']\n",
    "comparison['Linear Regression']=linear\n",
    "comparison['KNeighbors Regression']=kneighbor\n",
    "comparison['Ridge Regression']=ridge\n",
    "comparison['Lasso Regression']=lasso\n",
    "comparison['Neural Network Regression']=neural\n",
    "comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
